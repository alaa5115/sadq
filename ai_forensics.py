import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam 
import numpy as np
from PIL import Image
import io
import cv2
import base64 
from tf_keras_vis.gradcam import Gradcam 
from tf_keras_vis.utils.model_modifiers import ReplaceToLinear 
from tf_keras_vis.utils import normalize 

# Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø°ÙŠ ÙŠØªØ·Ù„Ø¨Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 
IMG_SIZE = 128

# =========================================================
# 1. Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN Ø§Ù„Ù…ÙØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ
# =========================================================

def build_forensics_model():
    """Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© ØªÙ„Ø§ÙÙŠÙÙŠØ© (CNN) Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØªÙ„Ø§Ø¹Ø¨."""
    
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
        MaxPooling2D((2, 2)),
        
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        
        Flatten(),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid') 
    ])
    
    model.compile(optimizer=Adam(learning_rate=0.0001), 
                  loss='binary_crossentropy', 
                  metrics=['accuracy'])
    
    return model

# =========================================================
# 2. Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# =========================================================

def analyze_with_ai(image_stream, global_model, ela_weight, prnu_score):
    """
    ØªØ´ØºÙŠÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ­Ù…Ù‘Ù„ Ø¹Ø§Ù„Ù…ÙŠØ§Ù‹.
    """
    
    # ØªÙ‡ÙŠØ¦Ø© Ù‚ÙŠÙ… Ø§Ù„ÙØ´Ù„
    ai_trust_score = 0.0
    gradcam_base64_image = None
    ai_msg = "âŒ Ù„Ù… ÙŠØªÙ… Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ."
    
    try:
        # 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø©
        image_stream.seek(0)
        original_img = Image.open(image_stream).convert('RGB')
        
        # ØªØ­Ø¬ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ù„ØªÙ†Ø§Ø³Ø¨ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (128x128)
        img = original_img.resize((IMG_SIZE, IMG_SIZE), Image.Resampling.LANCZOS)
        img_np = np.array(img, dtype=np.float32) / 255.0
        
        # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: (1, 128, 128, 3)
        input_tensor = np.expand_dims(img_np, axis=0)

        # 2. Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        prediction = global_model.predict(input_tensor)[0][0]
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¥Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ø£ØµØ§Ù„Ø© (0=Ù…Ø²ÙˆØ±ØŒ 1=Ø£ØµÙŠÙ„).
        ai_trust_score = float(prediction * 100) # ğŸ’¡ Ø§Ù„Ø¥ØµÙ„Ø§Ø­: ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ float Ù‚ÙŠØ§Ø³ÙŠ

        # 3. ØªÙˆÙ„ÙŠØ¯ Ø®Ø±ÙŠØ·Ø© Grad-CAM Ø§Ù„ØªÙØ³ÙŠØ±ÙŠØ©
        original_img_np = np.array(original_img.copy())
        
        try:
            # ØªØ­Ø¯ÙŠØ¯ Ø¢Ø®Ø± Ø·Ø¨Ù‚Ø© ØªÙ„Ø§ÙÙŠÙÙŠØ© (Conv2D) ÙƒÙ‡Ø¯Ù Ù„Ù„Ø±Ø¤ÙŠØ©
            candidate_layers = [layer.name for layer in global_model.layers if 'conv2d' in layer.name.lower()]
            
            if candidate_layers:
                target_layer = candidate_layers[-1] 

                # ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ù‡Ø¯Ù Ù„Ù€ Grad-CAM (Ù„Ù„ÙƒØ´Ù Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ)
                def loss(output):
                    # Ù†Ø³ØªØ®Ø¯Ù… Ø¯Ø§Ù„Ø© Ù„Ø§ Ø´ÙŠØ¡ Ø¨Ø³ÙŠØ·Ø©
                    return (output * 0) + 1 
                
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Gradcam Ù…Ø¹ Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ Keras-Vis
                gradcam = Gradcam(global_model, clone=True)
                                  
                # ØªÙˆÙ„ÙŠØ¯ Ø®Ø±ÙŠØ·Ø© Grad-CAM
                cam = gradcam(loss, input_tensor, penultimate_layer=target_layer, visualize_cam=True)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø®Ø±ÙŠØ·Ø©
                heatmap = np.uint8(cv2.resize(cam[0], (original_img.width, original_img.height), 
                                                 interpolation=cv2.INTER_LINEAR) * 255)
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ BGR Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… cv2.applyColorMap
                original_img_cv = cv2.cvtColor(original_img_np, cv2.COLOR_RGB2BGR) 
                heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
                
                # Ø¯Ù…Ø¬ Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
                superimposed_img = cv2.addWeighted(original_img_cv, 0.6, heatmap_colored, 0.4, 0)
                
                # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Base64
                heatmap_img = Image.fromarray(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))
                buffer = io.BytesIO()
                heatmap_img.save(buffer, format="PNG")
                gradcam_base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')
                
                ai_msg = f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø®Ø±ÙŠØ·Ø© Grad-CAM Ø¨Ù†Ø¬Ø§Ø­. (Ø¯Ø±Ø¬Ø© AI: {ai_trust_score:.2f}%)"
            else:
                raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø·Ø¨Ù‚Ø© Conv2D.")

        except Exception as e:
            # Ø±Ø³Ø§Ù„Ø© ØªØ®Ø¨Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨ÙØ´Ù„ Grad-CAM ÙÙ‚Ø·ØŒ Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†Ø¨Ø¤
            print(f"Error in Grad-CAM generation: {e}")
            ai_msg = f"ğŸŸ¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù†Ø¬Ø­ ({ai_trust_score:.2f}%)ØŒ Ù„ÙƒÙ† ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø®Ø±ÙŠØ·Ø© Grad-CAM Ø§Ù„ØªÙØ³ÙŠØ±ÙŠØ©."

            
    except Exception as e:
        # ÙØ´Ù„ Ø­Ø§Ø¯ ÙÙŠ Ø£ÙŠ Ø®Ø·ÙˆØ© Ù‚Ø¨Ù„ Ø£Ùˆ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        print(f"Critical error in AI analysis: {e}")
        ai_msg = f"âŒ ÙØ´Ù„ Ø­Ø§Ø¯ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© AI: {str(e)}"
        
    # 5. Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    # Ø§Ù„ÙˆØ²Ù†: 40% Ù„Ù€ AIØŒ 30% Ù„Ù€ PRNUØŒ 30% Ù„Ù€ ELA
    final_score_unclamped = (0.4 * ai_trust_score) + (0.3 * prnu_score) + (0.3 * ela_weight)
    final_score = np.clip(final_score_unclamped, 0.0, 100.0) 

    # 6. Ø¨Ù†Ø§Ø¡ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    if final_score < 50 and not "ÙØ´Ù„ Ø­Ø§Ø¯" in ai_msg:
        ai_msg = f"âš ï¸ ÙŠØ´ØªØ¨Ù‡ ÙÙŠ Ø§Ù„ØªÙ„Ø§Ø¹Ø¨/Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¢Ù„ÙŠ! Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ø£ØµØ§Ù„Ø©: {ai_trust_score:.2f}%."
    elif final_score >= 80:
        if "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯" not in ai_msg:
             ai_msg = f"âœ… Ù…ÙˆØ«ÙˆÙ‚ Ø¨Ù‡ Ø¬Ø¯Ø§Ù‹! Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ø£ØµØ§Ù„Ø©: {ai_trust_score:.2f}%."
        # Ù„Ø§ Ù†ØºÙŠØ± Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙØ´Ù„ ÙÙŠ Grad-CAM
    elif final_score >= 50 and not "ÙØ´Ù„ Ø­Ø§Ø¯" in ai_msg:
        if "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯" not in ai_msg:
            ai_msg = f"ğŸŸ¡ Ø¯Ø±Ø¬Ø© Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø© ÙÙŠ Ø§Ù„Ø£ØµØ§Ù„Ø©: {ai_trust_score:.2f}%. ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚."
        
    # 7. Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    return float(final_score), ai_msg, gradcam_base64_image, float(ai_trust_score)