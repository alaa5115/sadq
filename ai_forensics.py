import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam 
import numpy as np
from PIL import Image, ImageChops # ImageChops Ø¶Ø±ÙˆØ±ÙŠØ© Ù„Ù€ ELA
import io
import cv2
import base64 
from tf_keras_vis.gradcam import Gradcam 
from tf_keras_vis.utils.model_modifiers import ReplaceToLinear 
from tf_keras_vis.utils import normalize 

# Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…Ù† Ù…Ù„Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
try:
    from prnu_analysis import extract_noise_pattern
except ImportError:
    print("WARNING: ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ prnu_analysis. Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø³ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ AI Ùˆ ELA ÙÙ‚Ø·.")
    def extract_noise_pattern(image_stream):
        # Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù€ PRNU ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„
        return "âŒ Ù…Ø­Ø§ÙƒØ§Ø©: ØªØ­Ù„ÙŠÙ„ PRNU ØºÙŠØ± Ù…ØªÙˆÙØ±", 0.0, None

# Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø°ÙŠ ÙŠØªØ·Ù„Ø¨Ù‡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 
IMG_SIZE = 128
MODEL_PATH = 'forensics_model.h5'

# =========================================================
# 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ­Ù…ÙŠÙ„Ù‡
# =========================================================

# (Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒÙ…Ø§ Ù‡Ùˆ ÙÙŠ Ù…Ù„ÙÙƒØŒ Ù…Ø¹ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ forensics_model.h5)
def build_forensics_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid') 
    ])
    return model

try:
    LOADED_MODEL = load_model(MODEL_PATH)
    # ğŸŒŸğŸŒŸğŸŒŸ Ø§Ù„Ø¥ØµÙ„Ø§Ø­ 1: Ø¥Ø¶Ø§ÙØ© Ø§Ø³Ù… Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ù…Ù‘Ù„ ğŸŒŸğŸŒŸğŸŒŸ
    if not LOADED_MODEL.output_names:
        LOADED_MODEL.output_names = ['output_1']
        
    print(f"âœ… Ù†Ø¬Ø§Ø­: ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ AI Ù…Ù† {MODEL_PATH}")
except Exception as e:
# ... (Ø¨Ù‚ÙŠØ© Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ) ...
    print(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ AI: {e}. Ø³ÙŠØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ.")
    LOADED_MODEL = None


# =========================================================
# 2. Ø¯Ø§Ù„Ø© ØªØ­Ù„ÙŠÙ„ ELA (Error Level Analysis) - Ø§Ù„Ø¢Ù† ÙƒØ§Ù…Ù„Ø©
# =========================================================

def analyze_ela(image_stream, quality=95, scale_factor=15):
    """
    ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø£ (ELA) Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØªÙŠ ØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§.
    ØªÙ‚ÙˆÙ… Ø¨Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø«Ù… Ø¥Ø¹Ø§Ø¯Ø© ÙØªØ­Ù‡Ø§ Ø¨Ø¶ØºØ· 95% Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„ÙØ±Ù‚.
    """
    image_stream.seek(0)
    original_img = Image.open(image_stream).convert('RGB')
    
    # 1. Ø¥Ø¹Ø§Ø¯Ø© Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¬ÙˆØ¯Ø© Ø£Ù‚Ù„ (95%)
    ela_buffer = io.BytesIO()
    original_img.save(ela_buffer, format='JPEG', quality=quality)
    ela_buffer.seek(0)
    compressed_img = Image.open(ela_buffer).convert('RGB')
    
    # 2. Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ±Ù‚ (Error) Ø¨ÙŠÙ† Ø§Ù„Ø£ØµÙ„ ÙˆØ§Ù„Ù…Ø¶ØºÙˆØ·
    diff = ImageChops.difference(original_img, compressed_img)
    
    # 3. ØªØ¶Ø®ÙŠÙ… Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ù„Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ø±Ø¤ÙŠØ© (Scaling)
    # Ù†Ø³ØªØ®Ø¯Ù… Ø¹Ø§Ù…Ù„ Ù…Ù‚ÙŠØ§Ø³ Ù„ØªØ¶Ø®ÙŠÙ… Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø§Ù„Ù„ÙˆÙ†ÙŠØ©
    diff_array = np.array(diff).astype(np.float32) * scale_factor
    diff_array = np.clip(diff_array, 0, 255).astype(np.uint8)
    ela_img = Image.fromarray(diff_array)

    # 4. Ø­ÙØ¸ ØµÙˆØ±Ø© ELA Ø§Ù„Ù…Ø´ÙØ±Ø© Ù„ØºØ±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    ela_img_buffer = io.BytesIO()
    ela_img.save(ela_img_buffer, format='PNG')
    ela_base64_image = base64.b64encode(ela_img_buffer.getvalue()).decode('utf-8')
    
    # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© (ØªØ¨Ø³ÙŠØ·: Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø®ØªÙ„Ø§Ù)
    mean_error = np.mean(diff_array)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø¯Ø±Ø¬Ø© ELA
    if mean_error < 5.0:
        ela_score = 90.0 # Ø£ØµØ§Ù„Ø© Ø¹Ø§Ù„ÙŠØ©
        ela_verdict = f"âœ… ØªØ¨Ø§ÙŠÙ† Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹ ÙÙŠ ELA ({mean_error:.2f})."
    elif mean_error < 15.0:
        ela_score = 75.0 # Ø·Ø¨ÙŠØ¹ÙŠ
        ela_verdict = f"ğŸŸ¡ ØªØ¨Ø§ÙŠÙ† Ø·Ø¨ÙŠØ¹ÙŠ ÙÙŠ ELA ({mean_error:.2f})."
    else:
        ela_score = 30.0 # ØªØ²ÙˆÙŠØ±
        ela_verdict = f"âŒ ØªØ¨Ø§ÙŠÙ† Ø¹Ø§Ù„Ù ÙÙŠ ELA ({mean_error:.2f}). ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ù†Ø§Ø·Ù‚ Ù…Ø¹Ø¯Ù„Ø©."
        
    return ela_score, ela_verdict, ela_base64_image


# =========================================================
# 3. Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„Ø©
# =========================================================

def analyze_full_forensics(image_stream):
    
    # ----------------------------------------------------
    # Ø£. Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ÙŠØ§Ù†Ø§Øª EXIF Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    # ----------------------------------------------------
    image_stream.seek(0)
    img = Image.open(image_stream)
    metadata = {
        'make': img.getexif().get(271) if img.getexif() else 'ØºÙŠØ± Ù…ØªÙˆÙØ±',
        'model': img.getexif().get(272) if img.getexif() else 'ØºÙŠØ± Ù…ØªÙˆÙØ±',
        'datetime': img.getexif().get(36867) if img.getexif() else 'ØºÙŠØ± Ù…ØªÙˆÙØ±',
        'format': img.format,
        'size': f"{img.width}x{img.height}",
    }
    
    # ----------------------------------------------------
    # Ø¨. ØªØ­Ù„ÙŠÙ„ PRNU
    # ----------------------------------------------------
    prnu_verdict, prnu_score, prnu_img_base64 = extract_noise_pattern(image_stream)
    
    # ----------------------------------------------------
    # Ø¬. ØªØ­Ù„ÙŠÙ„ ELA
    # ----------------------------------------------------
    ela_score, ela_verdict, ela_img_base64 = analyze_ela(image_stream)
    
    # ----------------------------------------------------
    # Ø¯. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (AI CNN)
    # ----------------------------------------------------
    ai_trust_score = 50.0 
    gradcam_img_base64 = None
    ai_verdict = "âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ØºÙŠØ± ÙØ¹Ø§Ù„)."

    if LOADED_MODEL:
        try:
            image_stream.seek(0)
            img_resized = Image.open(image_stream).convert('RGB').resize((IMG_SIZE, IMG_SIZE))
            img_array = np.array(img_resized) / 255.0
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            prediction = LOADED_MODEL.predict(np.expand_dims(img_array, axis=0))
            ai_trust_score = (1.0 - prediction[0][0]) * 100.0 # Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ø£ØµØ§Ù„Ø©

            if ai_trust_score > 70:
                ai_verdict = f"âœ… ØªØ­Ù„ÙŠÙ„ AI: Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø£ØµØ§Ù„Ø© ({ai_trust_score:.2f}%)"
            elif ai_trust_score > 40:
                ai_verdict = f"ğŸŸ¡ ØªØ­Ù„ÙŠÙ„ AI: Ù†ØªÙŠØ¬Ø© Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡Ø§. ({ai_trust_score:.2f}%)"
            else:
                ai_verdict = f"âŒ ØªØ­Ù„ÙŠÙ„ AI: ÙƒØ´Ù ØªÙ„Ø§Ø¹Ø¨ Ø£Ùˆ ØªÙˆÙ„ÙŠØ¯ Ø¢Ù„ÙŠ. ({ai_trust_score:.2f}%)"
            
            # ----------------------------------------------------
            # Ù‡Ù€. Ù…Ù†Ø·Ù‚ ØªÙˆÙ„ÙŠØ¯ Grad-CAM (Ù„Ù„ØªÙØ³ÙŠØ±)
            # ----------------------------------------------------
            # ÙŠØ¬Ø¨ ØªØ¹Ø±ÙŠÙ Ø¯Ø§Ù„Ø© Ø§Ù„Ù‡Ø¯Ù Ù‡Ù†Ø§ØŒ ÙˆÙ„ØºØ±Ø¶ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
            def loss(output):
                return (output[0][0])
                
            gradcam = Gradcam(LOADED_MODEL, model_modifier=ReplaceToLinear(), clone=True)
            cam = gradcam(loss, img_array[np.newaxis, ...], penultimate_layer=-1)
            heatmap = np.uint8(cam[0] * 255)
            
            # Ø­ÙØ¸ ØµÙˆØ±Ø© Grad-CAM
            gradcam_img = Image.fromarray(heatmap, 'L').convert('RGB')
            gradcam_img_buffer = io.BytesIO()
            gradcam_img.save(gradcam_img_buffer, format='PNG')
            gradcam_img_base64 = base64.b64encode(gradcam_img_buffer.getvalue()).decode('utf-8')
            
        except Exception as e:
            print(f"Critical error in AI analysis/GradCAM: {e}")

        
    # ----------------------------------------------------
    # Ùˆ. Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    # ----------------------------------------------------
    
    final_score_unclamped = (0.4 * ai_trust_score) + (0.3 * prnu_score) + (0.3 * ela_score)
    final_score = np.clip(final_score_unclamped, 0.0, 100.0) 

    # Ø¨Ù†Ø§Ø¡ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø£Ù…Ù†ÙŠ (Ø§Ù„Ø®ØªÙ…)
    if final_score < 40:
        abshr_verdict = "FORGED"
    elif final_score < 75:
        abshr_verdict = "CAUTION"
    else:
        abshr_verdict = "CLEAN"
        
    
    # ----------------------------------------------------
    # Ø². ØªØ¬Ù…ÙŠØ¹ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù‚Ø§Ù…ÙˆØ³ ÙˆØ§Ø­Ø¯
    # ----------------------------------------------------
    
    analysis_results = {
        'final_score': final_score,
        'abshr_verdict': abshr_verdict,
        'metadata': metadata,
        
        'ai_score': ai_trust_score,
        'ai_verdict': ai_verdict,
        'gradcam_img_base64': gradcam_img_base64,
        
        'prnu_score': prnu_score,
        'prnu_verdict': prnu_verdict,
        'prnu_img_base64': prnu_img_base64,
        
        'ela_score': ela_score,
        'ela_verdict': ela_verdict,
        'ela_img_base64': ela_img_base64,
        
        # Ù†Ø­ØªØ§Ø¬ Ø§Ù„Ø£ØµÙ„ Ù„ÙŠÙƒÙˆÙ† ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        'original_img_base64': base64.b64encode(image_stream.getvalue()).decode('utf-8') if image_stream else None
    }
        
    return analysis_results